{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b9bf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch-audiomentations\n",
    "!pip install -q torchaudio\n",
    "!pip install -q julius\n",
    "!pip install -q pesq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "027cb5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "from IPython.display import Audio\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import librosa\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5bfd440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#人聲: 116969 \n",
      "#消防車聲: 200 \n",
      "#工地聲: 11997\n"
     ]
    }
   ],
   "source": [
    "speak_files=glob(\"../../datas/cv-corpus-9.0-2022-04-27/zh-TW/clips/*.mp3\")\n",
    "firetruck_files=glob(\"../../datas/sounds/firetruck/*.wav\")\n",
    "construction_files=glob(\"../../datas/sounds/splited_construction/*.wav\")\n",
    "print(\n",
    "    \"#人聲:\",len(speak_files),\n",
    "    \"\\n#消防車聲:\",len(firetruck_files),\n",
    "    \"\\n#工地聲:\",len(construction_files)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cba21dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=2022):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51127de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def split(x,test_val_ratio):\n",
    "    x0,x1=train_test_split(x,test_size=sum(test_val_ratio))\n",
    "    x1,x2=train_test_split(x1,test_size=test_val_ratio[-1])\n",
    "    return x0,x1,x2\n",
    "set_seed(2022)\n",
    "sig_train,sig_val,sig_test=split(speak_files,(0.1,0.1))\n",
    "art_train,art_val,art_test=split(firetruck_files,(0.1,0.1))\n",
    "noise_train,noise_val,noise_test=split(construction_files,(0.1,0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f7fced7",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=28\n",
    "SAMPLE_RATE=16000\n",
    "BATCH_SIZE=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c52765db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as tud\n",
    "import sirenns.datasets.loader as ldr\n",
    "L=16000*4\n",
    "common_kwargs=dict(\n",
    "    signal_len=L,\n",
    "    transform=ldr.transform,\n",
    "    artifact_transform=ldr.artifact_noise_transform,\n",
    "    noise_transform=ldr.artifact_noise_transform\n",
    ")\n",
    "\n",
    "train_ds=ldr.SyntheticCallDataset(sig_train,\n",
    "                              artifact_files=art_train,\n",
    "                              noise_files=noise_train,\n",
    "                              **common_kwargs)\n",
    "train_dl=tud.DataLoader(train_ds,batch_size=BATCH_SIZE,collate_fn=train_ds.collate_fn)\n",
    "\n",
    "val_ds=ldr.SyntheticCallDataset(sig_val,\n",
    "                              artifact_files=art_val,\n",
    "                              noise_files=noise_val,\n",
    "                              **common_kwargs)\n",
    "val_dl=tud.DataLoader(val_ds,batch_size=BATCH_SIZE,collate_fn=val_ds.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb7f9cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 179 ms, sys: 34.4 ms, total: 214 ms\n",
      "Wall time: 115 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for  batch in val_dl:\n",
    "    x,signal,artifact,noise= batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfb9c006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SEED=3\n",
    "# Audio(x[BATCH_SEED].cpu() ,rate=8000,normalize=False)\n",
    "# Audio(signal[BATCH_SEED].cpu() ,rate=16000,normalize=False)\n",
    "# Audio(artifact[BATCH_SEED].cpu() ,rate=16000,normalize=False)\n",
    "# Audio(noise[BATCH_SEED].cpu() ,rate=16000,normalize=False)\n",
    "# plt.plot(artifact[BATCH_SEED,0].cpu().numpy().T,alpha=0.9)\n",
    "# plt.plot(noise[BATCH_SEED,0].cpu().numpy().T,alpha=0.7)\n",
    "# plt.plot(signal[BATCH_SEED,0].cpu().numpy().T,alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1470b8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchaudio.models import ConvTasNet\n",
    "import torch.nn as nn\n",
    "import sirenns.utils.losses as lsf \n",
    "net=ConvTasNet(num_sources=3,\n",
    "               enc_num_feats=256,\n",
    "               msk_num_hidden_feats=128\n",
    "              ).cuda()\n",
    "# Loss cocmbo 1: MSE+SGD\n",
    "# criterion = nn.MSELoss()\n",
    "# optimizer = torch.optim.SGD(net.parameters(),lr=1e-3,momentum=0.9,weight_decay=0.0005)\n",
    "# Loss cocmbo 2: SDR+clip norm+Adam\n",
    "criterion = lambda y,pred: lsf.cal_loss(y,pred,float(L))\n",
    "# Clip Norm\n",
    "for p in net.parameters():\n",
    "    p.register_hook(lambda grad: torch.clamp(grad, -5, 5))\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37f8dfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "lamb=[0.8,0.1,0.1]\n",
    "def one_batch(i_iter,log,sample_batched,model,criterion,optimizer):\n",
    "    # Prep input\n",
    "    x,signal,artifact,noise=[_ for _ in sample_batched]\n",
    "    x=F.interpolate(x,scale_factor=2,mode=\"linear\")\n",
    "    pred=model(x)\n",
    "    loss = criterion(pred[:,0:1], signal)*lamb[0]+\\\n",
    "           criterion(pred[:,1:2], artifact)*lamb[1]+\\\n",
    "           criterion(pred[:,2:3], noise)*lamb[2]\n",
    "    if model.training:\n",
    "        #Update\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    with torch.no_grad():\n",
    "        loss_sig=criterion(pred[:,0:1], signal).item()\n",
    "        if i_iter==0:\n",
    "            log['loss_sig'] = loss_sig\n",
    "        else:\n",
    "            log['loss_sig'] = (loss_sig+log['loss_sig']*i_iter)/(i_iter + 1)\n",
    "    # Record\n",
    "    loss_rec = loss.item()\n",
    "    log['loss'] = (loss_rec+log['loss']*i_iter)/(i_iter + 1)\n",
    "    return pred,loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9dafbf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "os.makedirs(\"../snapshots\",exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f64d9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "46788it [2:47:14,  4.66it/s, epoch=0, step=46785, loss=-6.82, loss_sig=-8.78]\n",
      "10527it [21:46,  8.06it/s, epoch=0, step=val, loss=-7.47, loss_sig=-9.42]\n",
      "46788it [2:47:26,  4.66it/s, epoch=1, step=46785, loss=-7.64, loss_sig=-9.55]\n",
      "10527it [21:47,  8.05it/s, epoch=1, step=val, loss=-7.87, loss_sig=-9.8] \n",
      "46788it [2:47:43,  4.65it/s, epoch=2, step=46785, loss=-7.95, loss_sig=-9.84]\n",
      "10527it [21:46,  8.06it/s, epoch=2, step=val, loss=-8.12, loss_sig=-10] \n",
      "46788it [2:47:40,  4.65it/s, epoch=3, step=46785, loss=-8.16, loss_sig=-10]  \n",
      "10527it [21:44,  8.07it/s, epoch=3, step=val, loss=-8.18, loss_sig=-10.1]\n",
      "46788it [2:47:32,  4.65it/s, epoch=4, step=46785, loss=-8.29, loss_sig=-10.2]\n",
      "10527it [21:44,  8.07it/s, epoch=4, step=val, loss=-8.27, loss_sig=-10.2]\n",
      "46788it [2:47:26,  4.66it/s, epoch=5, step=46785, loss=-8.39, loss_sig=-10.3]\n",
      "10527it [21:44,  8.07it/s, epoch=5, step=val, loss=-8.41, loss_sig=-10.3]\n",
      "46788it [2:47:31,  4.65it/s, epoch=6, step=46785, loss=-8.49, loss_sig=-10.4]\n",
      "10527it [21:45,  8.06it/s, epoch=6, step=val, loss=-8.5, loss_sig=-10.4] \n",
      "46788it [2:47:32,  4.65it/s, epoch=7, step=46785, loss=-8.58, loss_sig=-10.5]\n",
      "10527it [21:45,  8.06it/s, epoch=7, step=val, loss=-8.59, loss_sig=-10.5]\n",
      "46788it [2:47:29,  4.66it/s, epoch=8, step=46785, loss=-8.61, loss_sig=-10.5]\n",
      "10527it [21:48,  8.05it/s, epoch=8, step=val, loss=-8.56, loss_sig=-10.5]\n",
      "46788it [2:47:35,  4.65it/s, epoch=9, step=46785, loss=-8.65, loss_sig=-10.5]\n",
      "10527it [21:50,  8.03it/s, epoch=9, step=val, loss=-8.62, loss_sig=-10.5]\n",
      "46788it [2:47:44,  4.65it/s, epoch=10, step=46785, loss=-8.69, loss_sig=-10.6]\n",
      "10527it [21:50,  8.03it/s, epoch=10, step=val, loss=-8.61, loss_sig=-10.5]\n",
      "46788it [2:47:56,  4.64it/s, epoch=11, step=46785, loss=-8.76, loss_sig=-10.6]\n",
      "10527it [21:50,  8.04it/s, epoch=11, step=val, loss=-8.66, loss_sig=-10.6]\n",
      "46788it [2:47:57,  4.64it/s, epoch=12, step=46785, loss=-8.77, loss_sig=-10.6]\n",
      "10527it [21:48,  8.05it/s, epoch=12, step=val, loss=-8.69, loss_sig=-10.6]\n",
      "46788it [2:47:57,  4.64it/s, epoch=13, step=46785, loss=-8.79, loss_sig=-10.7]\n",
      "10527it [21:50,  8.04it/s, epoch=13, step=val, loss=-8.74, loss_sig=-10.6]\n",
      "46788it [2:48:02,  4.64it/s, epoch=14, step=46785, loss=-8.82, loss_sig=-10.7]\n",
      "10527it [21:48,  8.04it/s, epoch=14, step=val, loss=-8.69, loss_sig=-10.6]\n",
      "46788it [2:48:15,  4.63it/s, epoch=15, step=46785, loss=-8.8, loss_sig=-10.7] \n",
      "10527it [21:51,  8.03it/s, epoch=15, step=val, loss=-8.74, loss_sig=-10.6]\n",
      "46788it [2:48:11,  4.64it/s, epoch=16, step=46785, loss=-8.85, loss_sig=-10.7]\n",
      "7982it [16:34,  8.01it/s, epoch=16, step=val, loss=-8.71, loss_sig=-10.6]"
     ]
    }
   ],
   "source": [
    "EPOCH=100\n",
    "net.train()\n",
    "best_loss=np.inf\n",
    "PAITIENCE=5\n",
    "count=0\n",
    "try:\n",
    "    for e in range(EPOCH):\n",
    "        log= {'epoch':e,'step':0,'loss': 0, 'loss_sig': 0}\n",
    "        net.train()\n",
    "        session=tqdm(enumerate(train_dl))\n",
    "        for i_iter, sample_batched in session:\n",
    "            pred,loss=one_batch(i_iter,log,sample_batched,net,criterion,optimizer)\n",
    "            # print loss and take snapshots\n",
    "            if (i_iter + 1) % 5 == 0:\n",
    "                log['step']=i_iter+1\n",
    "                session.set_postfix(log)\n",
    "        # validate\n",
    "        log = {'epoch':e,'step':'val','loss': 0, 'loss_sig': 0}\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            session=tqdm(enumerate(val_dl))\n",
    "            for i_iter,sample_batched in session:\n",
    "                \n",
    "                pred,loss=one_batch(i_iter,log,sample_batched,net,criterion,optimizer)\n",
    "                if (i_iter + 1) % 5 == 0:\n",
    "                    session.set_postfix(log)\n",
    "        # early stop        \n",
    "        if log[\"loss_sig\"]<best_loss:\n",
    "            best_loss=log[\"loss_sig\"]\n",
    "            torch.save(net.state_dict(), '../snapshots/best.pth')\n",
    "        elif count<=PAITIENCE: count+=1\n",
    "        else:\n",
    "            count=0\n",
    "            best_loss=np.inf\n",
    "            break \n",
    "            \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nHuman Interrupted\")\n",
    "torch.save(net.state_dict(), '../snapshots/latest.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "64492956",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds=ldr.SyntheticCallDataset(sig_test,\n",
    "                              artifact_files=art_test,\n",
    "                              noise_files=noise_test,\n",
    "                              **common_kwargs)\n",
    "test_dl=tud.DataLoader(test_ds,batch_size=BATCH_SIZE,collate_fn=test_ds.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "364d37e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pesq\n",
    "def mean_pesq(good,bad):\n",
    "    result=[]\n",
    "    for g,b in zip(np.squeeze(good),np.squeeze(bad)):\n",
    "        result.append(pesq.pesq(16000,g,b,mode=\"wb\",on_error=1))\n",
    "    return np.mean(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a4f00894",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "229it [06:30,  1.71s/it, epoch=11, step=val, loss=0.00114, loss_sig=0.00174, pesq_pre=1.24, pesq_post=1.24, pesq_diff=0.00601]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_48271/1395069573.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0martifact\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample_batched\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscale_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"linear\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msample_batched\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mpesq_pre\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmean_pesq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mpesq_post\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmean_pesq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_48271/521386863.py\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(i_iter, log, sample_batched, model, criterion, optimizer)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mloss_sig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi_iter\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_sig'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_sig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "log = {'epoch':e,\n",
    "       'step':'val',\n",
    "       'loss': 0,\n",
    "       'loss_sig': 0,\n",
    "       'pesq_pre': 0,\n",
    "       'pesq_post': 0,\n",
    "       'pesq_diff':999}\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    session=tqdm(enumerate(test_dl))\n",
    "    for i_iter,sample_batched in session:\n",
    "        x,signal,artifact,noise=[_ for _ in sample_batched]\n",
    "        x=F.interpolate(x,scale_factor=2,mode=\"linear\")\n",
    "        pred,loss=one_batch(i_iter,log,sample_batched,net,criterion,optimizer)\n",
    "        pesq_pre=mean_pesq(signal.cpu().numpy(),x.cpu().numpy())\n",
    "        pesq_post=mean_pesq(signal.cpu().numpy(),pred[:,0:1].cpu().numpy())\n",
    "        log['pesq_pre'] = (pesq_pre+log['pesq_pre']*i_iter)/(i_iter + 1)\n",
    "        log['pesq_post'] = (pesq_post+log['pesq_post']*i_iter)/(i_iter + 1)\n",
    "        log['pesq_diff'] =log['pesq_post']-log['pesq_pre']\n",
    "        if (i_iter + 1) % 5 == 0:\n",
    "            session.set_postfix(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f4e330b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch': 11,\n",
       " 'step': 'val',\n",
       " 'loss': 0.001225284591782838,\n",
       " 'loss_sig': 0.0020091817423235625,\n",
       " 'pesq_pre': 1.5318121959765751,\n",
       " 'pesq_post': 1.58041051030159,\n",
       " 'pesq_diff': 0.048598314325014824}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a60e4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
